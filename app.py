# app.py
# Ng·ªçcMinhCh√¢u-AI - Streamlit front-end (ƒë·∫ßy ƒë·ªß ch·ª©c nƒÉng)
# Y√™u c·∫ßu: ƒë√£ c√†i requirements, ƒë√£ set OPENAI_API_KEY trong env

import os
import io
import zipfile
import json
import tempfile
from datetime import datetime
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv

# t·∫£i env
load_dotenv()

# libs optional, try import and provide graceful fallback messages
try:
    import openai
except Exception:
    openai = None

try:
    import pandas as pd
except Exception:
    pd = None

try:
    import PyPDF2
except Exception:
    PyPDF2 = None

try:
    from PIL import Image
except Exception:
    Image = None

try:
    import pytesseract
except Exception:
    pytesseract = None

try:
    import speech_recognition as sr
except Exception:
    sr = None

try:
    import matplotlib.pyplot as plt
except Exception:
    plt = None

try:
    from sklearn.linear_model import LinearRegression
    import numpy as np
except Exception:
    LinearRegression = None
    np = None

# Config
st.set_page_config(page_title="Ng·ªçcMinhCh√¢u AI ‚Äî Tr·ª£ l√Ω h√†nh ch√≠nh", layout="wide", initial_sidebar_state="expanded")
ROOT = Path.cwd()
INPUT_DIR = ROOT / "input_data"
OUTPUT_DIR = ROOT / "output_data"
HISTORY_FILE = ROOT / "report_history" / "history.json"
for d in (INPUT_DIR, OUTPUT_DIR, ROOT / "report_history", ROOT / "logs"):
    d.mkdir(parents=True, exist_ok=True)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
if openai and OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

# ----------------------
# Helper: UI styling
# ----------------------
st.markdown(
    """
    <style>
    .sidebar .sidebar-content {
        background-image: linear-gradient(#0f172a,#0b1220);
        color: white;
    }
    .big-title {
        font-size:28px;
        font-weight:700;
        color:#073b4c;
    }
    .muted {
        color:#6b7280;
    }
    .card {
        border-radius:10px;
        padding:16px;
        background: linear-gradient(90deg, #ffffff, #f8fafc);
        box-shadow: 0 4px 12px rgba(16,24,40,0.06);
    }
    </style>
    """, unsafe_allow_html=True
)

# ----------------------
# Helper: utils
# ----------------------
def load_history():
    if HISTORY_FILE.exists():
        try:
            return json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
        except Exception:
            return []
    return []

def save_history(history):
    HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
    HISTORY_FILE.write_text(json.dumps(history, ensure_ascii=False, indent=2), encoding="utf-8")

def add_history(item: dict):
    h = load_history()
    h.append(item)
    save_history(h)

def allowed_file(filename):
    return any(filename.lower().endswith(ext) for ext in (".pdf", ".png", ".jpg", ".jpeg", ".tiff", ".xlsx", ".xls", ".csv", ".txt", ".docx", ".wav", ".mp3", ".flac"))

# ----------------------
# AI core simplified
# ----------------------
def openai_chat(prompt, system="B·∫°n l√† tr·ª£ l√Ω h√†nh ch√≠nh chuy√™n nghi·ªáp, vi·∫øt cho c√¥ng ch·ª©c x√£. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng."):
    if not openai:
        return "OpenAI library ch∆∞a c√†i. Th√™m openai v√†o requirements."
    if not OPENAI_API_KEY:
        return "ENV OPENAI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh."
    try:
        # use ChatCompletion
        resp = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role":"system","content":system},
                {"role":"user","content":prompt}
            ],
            temperature=0.2,
            max_tokens=800
        )
        text = resp.choices[0].message.content
        return text
    except Exception as e:
        return f"[L·ªói OpenAI] {e}"

def summarize_text(text, style="T√≥m t·∫Øt ng·∫Øn g·ªçn (b√°o c√°o h√†nh ch√≠nh)"):
    prompt = f"Please summarize and convert the following text into a {style} in Vietnamese. Provide clear sections: M·ª•c ti√™u, T√≥m t·∫Øt, Ph√¢n t√≠ch, ƒê·ªÅ xu·∫•t.\n\nText:\n{text[:4000]}"
    return openai_chat(prompt)

# ----------------------
# File extractors
# ----------------------
def extract_text_from_pdf(path):
    if not PyPDF2:
        return "[PyPDF2 ch∆∞a c√†i]"
    try:
        out = []
        with open(path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for p in reader.pages:
                t = p.extract_text()
                if t:
                    out.append(t)
        return "\n".join(out)
    except Exception as e:
        return f"[L·ªói PDF] {e}"

def extract_text_from_image(path):
    if not pytesseract or not Image:
        return "[PIL/pytesseract ch∆∞a c√†i]"
    try:
        img = Image.open(path)
        txt = pytesseract.image_to_string(img, lang="vie+eng")
        return txt
    except Exception as e:
        return f"[L·ªói OCR] {e}"

def extract_text_from_audio(path):
    if not sr:
        return "[SpeechRecognition ch∆∞a c√†i]"
    try:
        r = sr.Recognizer()
        with sr.AudioFile(path) as src:
            audio = r.record(src)
        txt = r.recognize_google(audio, language="vi-VN")
        return txt
    except Exception as e:
        return f"[L·ªói Speech->Text] {e}"

def extract_text_from_excel(path):
    if not pd:
        return "[pandas ch∆∞a c√†i]"
    try:
        df = pd.read_excel(path)
        return df, df.to_string()
    except Exception as e:
        return None, f"[L·ªói ƒë·ªçc Excel] {e}"

# ----------------------
# Forecast & anomaly (simple)
# ----------------------
def forecast_and_detect(df):
    if LinearRegression is None or np is None:
        return {}, {}
    numeric_cols = df.select_dtypes(include="number").columns
    forecasts = {}
    alerts = {}
    for c in numeric_cols:
        series = df[c].dropna().values
        if len(series) < 4:
            continue
        X = np.arange(len(series)).reshape(-1,1)
        model = LinearRegression().fit(X, series)
        pred = model.predict([[len(series)]])[0]
        forecasts[c] = float(pred)
        mean = float(np.mean(series)); std = float(np.std(series))
        anomalies = []
        for i, val in enumerate(series):
            if abs(val-mean) > 2*std:
                anomalies.append({"index": int(i), "value": float(val)})
        if anomalies:
            alerts[c] = anomalies
    return forecasts, alerts

# ----------------------
# Email & Zalo utilities
# ----------------------
import smtplib
from email.mime.text import MIMEText
import requests

def send_email_simple(subject, body, to_email=None):
    user = os.getenv("EMAIL_USER")
    pwd = os.getenv("EMAIL_PASSWORD")
    if not user or not pwd:
        return False, "EMAIL_USER/EMAIL_PASSWORD ch∆∞a c·∫•u h√¨nh"
    if not to_email:
        to_email = user
    try:
        msg = MIMEText(body, "plain", "utf-8")
        msg["Subject"] = subject
        msg["From"] = user
        msg["To"] = to_email
        server = smtplib.SMTP_SSL("smtp.gmail.com", 465, timeout=20)
        server.login(user, pwd)
        server.sendmail(user, [to_email], msg.as_string())
        server.quit()
        return True, "G·ª≠i email th√†nh c√¥ng"
    except Exception as e:
        return False, str(e)

def send_zalo_simple(text):
    token = os.getenv("ZALO_ACCESS_TOKEN")
    user_id = os.getenv("ZALO_USER_ID")
    if not token or not user_id:
        return False, "Zalo token/uid ch∆∞a c·∫•u h√¨nh"
    payload = {
        "recipient": {"user_id": user_id},
        "message": {"text": text},
        "access_token": token
    }
    try:
        r = requests.post("https://openapi.zalo.me/v2.0/oa/message", json=payload, timeout=10)
        return (r.status_code == 200), r.text
    except Exception as e:
        return False, str(e)

# ----------------------
# Simple semantic store (in-memory) using OpenAI embeddings if available
# ----------------------
VECTOR_STORE = []  # list of dict {id, text, embedding}

def embed_text(text):
    if not openai:
        return None
    try:
        emb = openai.Embedding.create(model="text-embedding-3-small", input=text)
        return emb["data"][0]["embedding"]
    except Exception:
        return None

def add_to_store(id_, text):
    emb = embed_text(text) if openai else None
    VECTOR_STORE.append({"id": id_, "text": text, "embedding": emb})

def semantic_search(query, top_k=3):
    if not openai or not VECTOR_STORE:
        return []
    q_emb = embed_text(query)
    if q_emb is None:
        return []
    # cosine similarity
    def cos(a,b):
        a = np.array(a); b = np.array(b)
        return float(np.dot(a,b) / (np.linalg.norm(a)*np.linalg.norm(b)+1e-9))
    scored = []
    for item in VECTOR_STORE:
        if item["embedding"] is None:
            continue
        s = cos(q_emb, item["embedding"])
        scored.append((s, item))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [x[1] for x in scored[:top_k]]

# ----------------------
# Streamlit App Layout
# ----------------------
st.markdown("<div class='big-title'>Ng·ªçcMinhCh√¢u AI ‚Äî Tr·ª£ l√Ω h√†nh ch√≠nh th√¥ng minh</div>", unsafe_allow_html=True)
st.write("Giao di·ªán t·ªëi gi·∫£n & chuy√™n nghi·ªáp ‚Äî Upload file, Chat, T√≥m t·∫Øt, Ph√¢n t√≠ch s·ªë li·ªáu, G·ª≠i th√¥ng b√°o.")

# Sidebar controls
with st.sidebar:
    st.header("C√†i ƒë·∫∑t nhanh")
    st.write("Tr·∫°ng th√°i OpenAI:", "OK" if OPENAI_API_KEY and openai else "Ch∆∞a c·∫•u h√¨nh")
    if st.button("Xem l·ªãch s·ª≠ x·ª≠ l√Ω"):
        st.experimental_set_query_params(tab="history")
    st.markdown("---")
    # Personalization: save writing style
    if "style_note" not in st.session_state:
        st.session_state.style_note = ""
    st.text_area("Ghi ch√∫ phong c√°ch (v√≠ d·ª•: trang tr·ªçng, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu):", key="style_note", height=80)
    if st.button("L∆∞u phong c√°ch"):
        st.success("ƒê√£ l∆∞u phong c√°ch c√° nh√¢n.")
    st.markdown("---")
    st.write("Phi√™n b·∫£n: 1.0 | ƒê∆∞·ª£c thi·∫øt k·∫ø cho c√¥ng ch·ª©c x√£")

# Main Tabs
tabs = st.tabs(["üè† Trang ch·ªß", "üí¨ Chat AI", "üìÇ Upload & X·ª≠ l√Ω", "üìà Ph√¢n t√≠ch Excel", "üìú L·ªãch s·ª≠", "‚öôÔ∏è C·∫•u h√¨nh & G·ª≠i"])

# --- Tab Home
with tabs[0]:
    st.subheader("Ch√†o m·ª´ng ƒë·∫øn v·ªõi Ng·ªçcMinhCh√¢u AI")
    st.info("M·ª•c ti√™u: h·ªó tr·ª£ so·∫°n th·∫£o vƒÉn b·∫£n, t·ªïng h·ª£p b√°o c√°o, ph√¢n t√≠ch s·ªë li·ªáu v√† t·ª± ƒë·ªông h√≥a quy tr√¨nh h√†nh ch√≠nh.")
    col1, col2 = st.columns([2,1])
    with col1:
        st.markdown("### Nhanh: th·ª≠ m·ªôt l·ªánh")
        q = st.text_input("H·ªèi AI m·ªôt c√¢u (v√≠ d·ª•: So·∫°n c√¥ng vƒÉn th√¥ng b√°o h·ªçp 10/10):")
        if st.button("G·ª≠i l·ªánh"):
            prompt = f"{st.session_state.get('style_note','')} \n\n{q}"
            with st.spinner("AI ƒëang suy nghƒ©..."):
                ans = openai_chat(prompt)
            st.markdown("**K·∫øt qu·∫£**")
            st.write(ans)
    with col2:
        st.markdown("### T√†i nguy√™n nhanh")
        st.write("- Upload file (tab Upload).")
        st.write("- Xem l·ªãch s·ª≠, t·∫£i b·∫£n sao l∆∞u (tab L·ªãch s·ª≠).")
        st.write("- C·∫•u h√¨nh email/Zalo ƒë·ªÉ g·ª≠i t·ª± ƒë·ªông (tab C·∫•u h√¨nh).")

# --- Tab Chat AI
with tabs[1]:
    st.subheader("Chat tr·ª±c ti·∫øp v·ªõi AI")
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    col_a, col_b = st.columns([3,1])
    with col_a:
        prompt = st.text_area("Nh·∫≠p c√¢u h·ªèi / y√™u c·∫ßu:", height=140)
        if st.button("G·ª≠i y√™u c·∫ßu"):
            full_prompt = (st.session_state.get("style_note","") + "\n\n" + prompt).strip()
            with st.spinner("G·ªçi OpenAI..."):
                resp = openai_chat(full_prompt)
            st.session_state.chat_history.append({"role":"user","text":prompt,"response":resp,"ts":datetime.now().isoformat()})
            add_history({"type":"chat","prompt":prompt,"response":resp,"timestamp":datetime.now().isoformat()})
            st.experimental_rerun()
    with col_b:
        st.markdown("**Phi√™n g·∫ßn ƒë√¢y**")
        for c in reversed(st.session_state.chat_history[-5:]):
            st.write(f"> **B·∫°n:** {c['text']}")
            st.write(f"**AI:** {c['response']}")

# --- Tab Upload & Processing
with tabs[2]:
    st.subheader("Upload file ƒë·ªÉ AI x·ª≠ l√Ω")
    uploaded = st.file_uploader("Ch·ªçn file (PDF, Image, Excel, Audio, DOCX)", accept_multiple_files=False)
    if uploaded:
        save_path = INPUT_DIR / uploaded.name
        with open(save_path, "wb") as f:
            f.write(uploaded.getbuffer())
        st.success(f"ƒê√£ l∆∞u: {save_path.name}")
        # extract text based on type
        txt = ""
        out_preview = ""
        if uploaded.name.lower().endswith(".pdf"):
            txt = extract_text_from_pdf(save_path)
            out_preview = txt[:2000]
        elif uploaded.name.lower().endswith((".png",".jpg",".jpeg",".tiff")):
            txt = extract_text_from_image(save_path)
            out_preview = txt[:2000]
        elif uploaded.name.lower().endswith((".wav",".mp3",".flac")):
            txt = extract_text_from_audio(save_path)
            out_preview = txt[:2000]
        elif uploaded.name.lower().endswith((".xls",".xlsx",".csv")):
            df, txt = extract_text_from_excel(save_path)
            out_preview = txt[:2000] if isinstance(txt,str) else str(df.head())
        elif uploaded.name.lower().endswith(".docx"):
            try:
                import docx
                doc = docx.Document(save_path)
                txt = "\n".join(p.text for p in doc.paragraphs)
                out_preview = txt[:2000]
            except Exception as e:
                txt = f"[L·ªói ƒë·ªçc docx] {e}"
        else:
            txt = uploaded.getvalue().decode(errors="ignore")
            out_preview = txt[:2000]

        st.markdown("### N·ªôi dung tr√≠ch xu·∫•t (xem nhanh)")
        st.text_area("Preview", out_preview, height=250)

        # semantic store add
        add_to_store(str(datetime.now().timestamp()), txt[:5000])

        # generate report
        st.markdown("### T·∫°o b√°o c√°o / t√≥m t·∫Øt")
        report_style = st.selectbox("Ch·ªçn ki·ªÉu b√°o c√°o", ["B√°o c√°o h√†nh ch√≠nh ng·∫Øn g·ªçn", "B√°o c√°o chi ti·∫øt", "Bi√™n b·∫£n h·ªçp", "C√¥ng vƒÉn", "K·∫ø ho·∫°ch"])
        if st.button("T·∫°o b√°o c√°o b·∫±ng AI"):
            with st.spinner("AI ƒëang t·∫°o b√°o c√°o..."):
                prompt = f"B·∫°n l√† tr·ª£ l√Ω h√†nh ch√≠nh. T·ª´ n·ªôi dung sau, so·∫°n th√†nh m·ªôt {report_style} b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, c√≥ m·ª•c l·ª•c, c√°c ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông:\n\n{txt[:6000]}"
                if st.session_state.style_note:
                    prompt = st.session_state.style_note + "\n\n" + prompt
                report = openai_chat(prompt)
                # save file
                tfn = OUTPUT_DIR / f"report_{uploaded.name}_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
                tfn.write_text(report, encoding="utf-8")
                add_history({"type":"report","source":uploaded.name,"path":str(tfn),"timestamp":datetime.now().isoformat(),"preview":report[:1000]})
                st.success("ƒê√£ t·∫°o b√°o c√°o")
                st.download_button("T·∫£i b√°o c√°o (TXT)", report, file_name=tfn.name)
                st.text_area("B√°o c√°o", report, height=360)

# --- Tab Excel Analysis
with tabs[3]:
    st.subheader("Ph√¢n t√≠ch Excel: d·ª± b√°o & ph√°t hi·ªán b·∫•t th∆∞·ªùng")
    excel_files = [f for f in INPUT_DIR.iterdir() if f.suffix.lower() in (".xlsx",".xls",".csv")]
    if excel_files:
        sel = st.selectbox("Ch·ªçn file Excel:", [f.name for f in excel_files])
        df = pd.read_excel(INPUT_DIR / sel)
        st.dataframe(df)
        if st.button("Ph√¢n t√≠ch & D·ª± b√°o"):
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                forecasts, alerts = forecast_and_detect(df)
                st.markdown("#### D·ª± b√°o")
                st.json(forecasts)
                if alerts:
                    st.warning("Ph√°t hi·ªán b·∫•t th∆∞·ªùng")
                    st.json(alerts)
                # chart first numeric column
                numeric = df.select_dtypes(include="number").columns.tolist()
                if numeric and plt:
                    col = numeric[0]
                    fig, ax = plt.subplots()
                    ax.plot(df[col].fillna(method="ffill").values)
                    ax.set_title(f"Bi·ªÉu ƒë·ªì {col}")
                    st.pyplot(fig)
    else:
        st.info("Ch∆∞a c√≥ file Excel trong input_data. Upload ·ªü tab Upload & X·ª≠ l√Ω.")

# --- Tab History
with tabs[4]:
    st.subheader("L·ªãch s·ª≠ & Backup")
    history = load_history()
    if not history:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ n√†o.")
    else:
        st.write(f"T·ªïng b·∫£n ghi: {len(history)}")
        for i, rec in enumerate(reversed(history[-50:]), 1):
            st.markdown(f"**{i}.** `{rec.get('type','?')}` ‚Äî {rec.get('timestamp')}")
            if rec.get("preview"):
                st.write(rec.get("preview"))
            if rec.get("path") and Path(rec["path"]).exists():
                with open(rec["path"], "rb") as fh:
                    st.download_button("T·∫£i file", fh, file_name=Path(rec["path"]).name)

    # backup all outputs
    if st.button("T·∫°o backup ZIP t·∫•t c·∫£ b√°o c√°o"):
        ts = datetime.now().strftime("%Y%m%d%H%M%S")
        zname = OUTPUT_DIR / f"backup_reports_{ts}.zip"
        with zipfile.ZipFile(zname, "w") as z:
            for f in OUTPUT_DIR.glob("report_*.txt"):
                z.write(f, arcname=f.name)
        with open(zname, "rb") as fh:
            st.download_button("T·∫£i ZIP backup", fh, file_name=zname.name)

# --- Tab Config & Send
with tabs[5]:
    st.subheader("C·∫•u h√¨nh & G·ª≠i th√¥ng b√°o")
    st.markdown("### C·∫•u h√¨nh email/Zalo (nh·ªØng bi·∫øn n√†y n√™n ƒë·∫∑t trong Environment tr√™n Render ho·∫∑c .env c·ª•c b·ªô)")
    st.write("EMAIL_USER, EMAIL_PASSWORD (App Password Gmail), ZALO_ACCESS_TOKEN, ZALO_USER_ID")
    st.markdown("### G·ª≠i th·ª≠ email / Zalo")
    col1, col2 = st.columns(2)
    with col1:
        to = st.text_input("G·ª≠i ƒë·∫øn (email)", value=os.getenv("EMAIL_USER",""))
        subject = st.text_input("Ti√™u ƒë·ªÅ", value="Th√¥ng b√°o t·ª´ Ng·ªçcMinhCh√¢u AI")
        body = st.text_area("N·ªôi dung", value="N·ªôi dung test", height=120)
        if st.button("G·ª≠i Email th·ª≠"):
            ok, msg = send_email_simple(subject, body, to)
            if ok:
                st.success("G·ª≠i email th√†nh c√¥ng")
            else:
                st.error(f"G·ª≠i email th·∫•t b·∫°i: {msg}")
    with col2:
        zalo_msg = st.text_area("N·ªôi dung Zalo", value="Test Zalo", height=120)
        if st.button("G·ª≠i Zalo th·ª≠"):
            ok, msg = send_zalo_simple(zalo_msg)
            if ok:
                st.success("G·ª≠i Zalo th√†nh c√¥ng")
            else:
                st.error(f"G·ª≠i Zalo th·∫•t b·∫°i: {msg}")

    st.markdown("---")
    st.markdown("### T√¨m ki·∫øm ng·ªØ nghƒ©a (semantic search)")
    q = st.text_input("Nh·∫≠p truy v·∫•n t√¨m ki·∫øm ng·ªØ nghƒ©a")
    if st.button("T√¨m ki·∫øm"):
        results = semantic_search(q)
        if not results:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu embedding ho·∫∑c OpenAI kh√¥ng c·∫•u h√¨nh.")
        else:
            for r in results:
                st.markdown(f"- **{r['id']}**: {r['text'][:300]}...")

# Footer
st.markdown("---")
st.write("¬© Ng·ªçcMinhCh√¢u AI ‚Äî Phi√™n b·∫£n demo. Li√™n h·ªá ƒë·ªÉ tri·ªÉn khai n√¢ng cao: c·∫•u h√¨nh vector DB, x√°c th·ª±c user, giao di·ªán chuy√™n nghi·ªáp h∆°n.")

